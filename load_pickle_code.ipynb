{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7b3a0l2ep4"
      },
      "source": [
        "1. mon_standard.pkl > array code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mfwrTwPtd36",
        "outputId": "22f73d36-41a3-4df6-86c9-74a28d36534f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n",
            "Total samples: 1900\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 95\n",
        "\n",
        "# Load the pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(\"mon_standard.pkl\", 'rb') as fi: # Path to mon_standard.pkl in Colab\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "X1_mon = [] # Array to store instances (timestamps) - 19,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2_mon = [] # Array to store instances (direction*size) - size information\n",
        "y_mon = [] # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
        "    for sample in data[i]:\n",
        "        size_seq = []\n",
        "        time_seq = []\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1\n",
        "            time_seq.append(abs(c))\n",
        "            size_seq.append(dr * 512)\n",
        "        X1_mon.append(time_seq)\n",
        "        X2_mon.append(size_seq)\n",
        "        y_mon.append(label)\n",
        "size = len(y_mon)\n",
        "\n",
        "print(f'Total samples: {size}') # Output: 19000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5mat0w2dJy"
      },
      "source": [
        "2. unmon_standard10.pkl > array code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWfcIOZovSMl",
        "outputId": "21d76456-9043-4335-ff3a-7c8c1b89f25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 3000\n",
            "300\n",
            "[-512 -512  512 ... -512 -512 -512]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "TOTAL_URLS = 300  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open('unmon_standard10_3000.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "X1_unmon = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2_unmon = [] # Array to store instances (direction*size) - size information\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "    for c in x[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
        "    X1_unmon.append(np.array(time_seq, dtype=np.int32))\n",
        "    X2_unmon.append(np.array(size_seq, dtype=np.int16))\n",
        "\n",
        "\n",
        "print(len(X1_unmon)) # Print the length of X1\n",
        "\n",
        "print(X2_unmon[0-10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBGa8u6_0pZ6"
      },
      "source": [
        "### Data Preprocessing ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBIIKY_i0pZ6"
      },
      "source": [
        "#### Remove corrupted/incomplete traces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4fBIcRD0pZ6",
        "outputId": "a598a24f-050a-4a03-a276-8c06cb5641c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean monitored traces: 1900\n",
            "Clean unmonitored traces: 300\n"
          ]
        }
      ],
      "source": [
        "def clean(X1, X2, y=None):\n",
        "    X1_clean, X2_clean, y_clean = [], [], []\n",
        "    for i in range(len(X1)):\n",
        "        if len(X1[i]) > 0 and len(X1[i]) == len(X2[i]): # non-empty & matching lengths\n",
        "            X1_clean.append(X1[i])\n",
        "            X2_clean.append(X2[i])\n",
        "            if y is not None:\n",
        "                y_clean.append(y[i])\n",
        "    return (X1_clean, X2_clean, y_clean) if y is not None else (X1_clean, X2_clean)\n",
        "\n",
        "# clean monitored\n",
        "X1_mon, X2_mon, y_mon = clean(X1_mon, X2_mon, y_mon)\n",
        "print(\"Clean monitored traces:\", len(X1_mon))\n",
        "\n",
        "# clean unmonitored\n",
        "X1_unmon, X2_unmon = clean(X1_unmon, X2_unmon)\n",
        "print(\"Clean unmonitored traces:\", len(X1_unmon))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSgGjkWI0pZ6"
      },
      "source": [
        "#### Normalize timestamps to start at 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F8NVpIuk0pZ7"
      },
      "outputs": [],
      "source": [
        "def normalize_timestamps(X1):\n",
        "    return [[t - seq[0] for t in seq] for seq in X1] # subtract by first seq value for each value to see how much time passed in each packet\n",
        "\n",
        "X1_mon = normalize_timestamps(X1_mon)\n",
        "X1_unmon = normalize_timestamps(X1_unmon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYjNUhF70pZ7"
      },
      "source": [
        "#### Truncate or pad sequences to certain length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzfsgqRS0pZ7",
        "outputId": "659c643e-0e93-4f2b-9e5b-1576fbfbd0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Monitored timestamps: (1900, 10000)\n",
            "Unmonitored timestamps: (300, 10000)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "MAX_LEN = 10000\n",
        "\n",
        "def pad_truncate(seq, max_len=10000):\n",
        "    seq = list(seq)  # assure une liste Python\n",
        "\n",
        "    if len(seq) > max_len:\n",
        "        return seq[:max_len]\n",
        "\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [0] * (max_len - len(seq))\n",
        "\n",
        "    return seq\n",
        "\n",
        "# --- MONITORED --------------------------------------------------------------\n",
        "X1_mon = np.array([pad_truncate(s, MAX_LEN) for s in X1_mon])\n",
        "X2_mon = np.array([pad_truncate(s, MAX_LEN) for s in X2_mon])\n",
        "y_mon = np.array(y_mon)\n",
        "\n",
        "# --- UNMONITORED ------------------------------------------------------------\n",
        "X1_unmon = np.array([pad_truncate(s, MAX_LEN) for s in X1_unmon])\n",
        "X2_unmon = np.array([pad_truncate(s, MAX_LEN) for s in X2_unmon])\n",
        "\n",
        "print(\"\\nMonitored timestamps:\", X1_mon.shape)\n",
        "print(\"Unmonitored timestamps:\", X1_unmon.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_L_u0Bh0pZ7"
      },
      "source": [
        "#### Split data into training, testing, and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zQx8iY3v0pZ7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) SCENARIO CLOSED WORLD\n",
        "\n",
        "X1_train_cw, X1_temp_cw, X2_train_cw, X2_temp_cw, y_train_cw, y_temp_cw = train_test_split(\n",
        "    X1_mon, X2_mon, y_mon,\n",
        "    test_size=0.30,\n",
        "    stratify=y_mon,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X1_val_cw, X1_test_cw, X2_val_cw, X2_test_cw, y_val_cw, y_test_cw = train_test_split(\n",
        "    X1_temp_cw, X2_temp_cw, y_temp_cw,\n",
        "    test_size=0.50,\n",
        "    stratify=y_temp_cw,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "X_train_cw = np.hstack((X1_train_cw, X2_train_cw))\n",
        "X_val_cw   = np.hstack((X1_val_cw,   X2_val_cw))\n",
        "X_test_cw  = np.hstack((X1_test_cw,  X2_test_cw))\n",
        "\n",
        "\n",
        "# 2) SCENARIO OPEN WORLD (binary 0/1)\n",
        "\n",
        "y_mon_binary = np.ones(len(X1_mon))        # SurveillÃ© = 1\n",
        "y_unmon_binary = np.zeros(len(X1_unmon))   # Non-surveillÃ© = 0\n",
        "\n",
        "# Combine les donnÃ©es\n",
        "X1_all = np.vstack((X1_mon, X1_unmon))\n",
        "X2_all = np.vstack((X2_mon, X2_unmon))\n",
        "y_all  = np.concatenate((y_mon_binary, y_unmon_binary))\n",
        "\n",
        "# Split open world\n",
        "X1_train_ow, X1_temp_ow, X2_train_ow, X2_temp_ow, y_train_ow, y_temp_ow = train_test_split(\n",
        "    X1_all, X2_all, y_all,\n",
        "    test_size=0.30,\n",
        "    stratify=y_all,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X1_val_ow, X1_test_ow, X2_val_ow, X2_test_ow, y_val_ow, y_test_ow = train_test_split(\n",
        "    X1_temp_ow, X2_temp_ow, y_temp_ow,\n",
        "    test_size=0.50,\n",
        "    stratify=y_temp_ow,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# fusion embedding\n",
        "X_train_ow = np.hstack((X1_train_ow, X2_train_ow))\n",
        "X_val_ow   = np.hstack((X1_val_ow,   X2_val_ow))\n",
        "X_test_ow  = np.hstack((X1_test_ow,  X2_test_ow))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch2OOgLljO_w"
      },
      "source": [
        "## **KNN MODEL** (Alice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "b8T1gciYjbAd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Closed World Scaler ---\n",
        "scaler_cw = StandardScaler()\n",
        "\n",
        "# Fit only on training data\n",
        "scaler_cw.fit(X_train_cw)\n",
        "\n",
        "# Transform\n",
        "X_train_cw_scaled = scaler_cw.transform(X_train_cw)\n",
        "X_val_cw_scaled   = scaler_cw.transform(X_val_cw)\n",
        "X_test_cw_scaled  = scaler_cw.transform(X_test_cw)\n",
        "\n",
        "# --- Open World Scaler ---\n",
        "scaler_ow = StandardScaler()\n",
        "\n",
        "# Fit only on training data\n",
        "scaler_ow.fit(X_train_ow)\n",
        "\n",
        "# Transform\n",
        "X_train_ow_scaled = scaler_ow.transform(X_train_ow)\n",
        "X_val_ow_scaled   = scaler_ow.transform(X_val_ow)\n",
        "X_test_ow_scaled  = scaler_ow.transform(X_test_ow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic-BnnRBoxlc",
        "outputId": "0f38c257-580a-40a4-c467-15f4c9148c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CLOSED WORLD====\n",
            "Train accuracy Â  Â  Â  : 0.7894736842105263\n",
            "Validation accuracy Â : 0.6736842105263158\n",
            "Test accuracy Â  Â  Â  Â : 0.6701754385964912\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"=== CLOSED WORLD====\")\n",
        "\n",
        "# KNN model\n",
        "knn_cw = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
        "\n",
        "# Train\n",
        "knn_cw.fit(X_train_cw_scaled, y_train_cw)\n",
        "\n",
        "# Validation accuracy\n",
        "y_train_pred_cw = knn_cw.predict(X_train_cw_scaled)\n",
        "y_val_pred_cw  = knn_cw.predict(X_val_cw_scaled)\n",
        "y_test_pred_cw = knn_cw.predict(X_test_cw_scaled)\n",
        "\n",
        "\n",
        "# Test accuracy\n",
        "train_acc_cw = accuracy_score(y_train_cw, y_train_pred_cw)\n",
        "val_acc_cw   = accuracy_score(y_val_cw, y_val_pred_cw)\n",
        "test_acc_cw  = accuracy_score(y_test_cw, y_test_pred_cw)\n",
        "\n",
        "\n",
        "print(\"Train accuracy Â  Â  Â  :\", train_acc_cw)\n",
        "print(\"Validation accuracy Â :\", val_acc_cw)\n",
        "print(\"Test accuracy Â  Â  Â  Â :\", test_acc_cw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Closed world K-NN Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- CLOSED WORLD K-NN OPTIMIZATION (GRID SEARCH) ---\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "\n",
            "Best parameters found    : {'n_neighbors': 3, 'weights': 'distance'}\n",
            "Accuracy WITHOUT tuning  : 0.6737\n",
            "Accuracy WITH tuning     : 0.6807\n",
            "IMPROVEMENT: +0.0070\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"\\n--- CLOSED WORLD K-NN OPTIMIZATION (GRID SEARCH) ---\")\n",
        "\n",
        "# 1. Define parameters to test\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9],       # Test different neighbors\n",
        "    'weights': ['uniform', 'distance'] # Test weight modes\n",
        "}\n",
        "\n",
        "# 2. Run the search (cv=3 for faster execution)\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_knn.fit(X_train_cw_scaled, y_train_cw)\n",
        "\n",
        "# 3. Retrieve the best model\n",
        "best_knn_cw = grid_knn.best_estimator_\n",
        "tuned_acc_cw = best_knn_cw.score(X_test_cw_scaled, y_test_cw)\n",
        "\n",
        "print(f\"\\nBest parameters found    : {grid_knn.best_params_}\")\n",
        "print(f\"Accuracy WITHOUT tuning  : {test_acc_cw:.4f}\")\n",
        "print(f\"Accuracy WITH tuning     : {tuned_acc_cw:.4f}\")\n",
        "\n",
        "# 4. Display the gain\n",
        "gain = tuned_acc_cw - test_acc_cw\n",
        "if gain > 0:\n",
        "    print(f\"IMPROVEMENT: +{gain:.4f}\")\n",
        "else:\n",
        "    print(f\"ðŸ”¹ No significant improvement (default model was already good).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRk8pir-pjjG",
        "outputId": "0ed3cbfe-efaa-468e-8cbb-54ad929070ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== OPEN WORLD (binary 0=unmon, 1=mon) ===\n",
            "Train accuracy Â  Â  Â  : 0.9227272727272727\n",
            "Validation accuracy Â : 0.8757575757575757\n",
            "Test accuracy Â  Â  Â  Â : 0.8636363636363636\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== OPEN WORLD (binary 0=unmon, 1=mon) ===\")\n",
        "\n",
        "# KNN model\n",
        "knn_ow = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
        "\n",
        "# Train\n",
        "knn_ow.fit(X_train_ow_scaled, y_train_ow)\n",
        "\n",
        "y_train_pred_ow = knn_ow.predict(X_train_ow_scaled)\n",
        "y_val_pred_ow   = knn_ow.predict(X_val_ow_scaled)\n",
        "y_test_pred_ow  = knn_ow.predict(X_test_ow_scaled)\n",
        "\n",
        "# --- Calcul accuracy ---\n",
        "train_acc_ow = accuracy_score(y_train_ow, y_train_pred_ow)\n",
        "val_acc_ow   = accuracy_score(y_val_ow, y_val_pred_ow)\n",
        "test_acc_ow  = accuracy_score(y_test_ow, y_test_pred_ow)\n",
        "\n",
        "\n",
        "print(\"Train accuracy Â  Â  Â  :\", train_acc_ow)\n",
        "print(\"Validation accuracy Â :\", val_acc_ow)\n",
        "print(\"Test accuracy Â  Â  Â  Â :\", test_acc_ow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Open world K-NN Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- OPEN WORLD K-NN OPTIMIZATION (GRID SEARCH) ---\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "\n",
            "Best parameters found    : {'n_neighbors': 9, 'weights': 'uniform'}\n",
            "Accuracy WITHOUT tuning  : 0.8636\n",
            "Accuracy WITH tuning     : 0.8909\n",
            "IMPROVEMENT: +0.0273\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"\\n--- OPEN WORLD K-NN OPTIMIZATION (GRID SEARCH) ---\")\n",
        "\n",
        "# 1. Define parameters to test\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9],       # Test different neighbors\n",
        "    'weights': ['uniform', 'distance'] # Test weight modes\n",
        "}\n",
        "\n",
        "# 2. Run the search (cv=3 for faster execution)\n",
        "# Note: We use the Open World variables (_ow) here\n",
        "grid_knn_ow = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_knn_ow.fit(X_train_ow_scaled, y_train_ow)\n",
        "\n",
        "# 3. Retrieve the best model\n",
        "best_knn_ow = grid_knn_ow.best_estimator_\n",
        "tuned_acc_ow = best_knn_ow.score(X_test_ow_scaled, y_test_ow)\n",
        "\n",
        "print(f\"\\nBest parameters found    : {grid_knn_ow.best_params_}\")\n",
        "print(f\"Accuracy WITHOUT tuning  : {test_acc_ow:.4f}\")\n",
        "print(f\"Accuracy WITH tuning     : {tuned_acc_ow:.4f}\")\n",
        "\n",
        "# 4. Display the gain\n",
        "gain_ow = tuned_acc_ow - test_acc_ow\n",
        "if gain_ow > 0:\n",
        "    print(f\"IMPROVEMENT: +{gain_ow:.4f}\")\n",
        "else:\n",
        "    print(f\"ðŸ”¹ No significant improvement (default model was already good).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtKCm2PSvs4Q"
      },
      "source": [
        "## **SVM (Alice)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jufyOJGvzj4",
        "outputId": "ef5d3519-77ce-4f94-94a3-7c5bbad79c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CLOSED WORLD (SVM) ====\n",
            "DÃ©marrage de l'entraÃ®nement...\n",
            "[LibSVM]Temps d'entraÃ®nement: 13.34 secondes\n",
            "\n",
            "--- RÃ‰SULTATS ---\n",
            "Train accuracy Â  Â  Â  : 0.8639097744360902\n",
            "Validation accuracy Â : 0.6456140350877193\n",
            "Test accuracy Â  Â  Â  Â : 0.6736842105263158\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "print(\"=== CLOSED WORLD (SVM) ====\")\n",
        "\n",
        "svm_cw = SVC(\n",
        "    kernel='rbf',\n",
        "    gamma='scale',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "start_time = time.time()\n",
        "print(\"DÃ©marrage de l'entraÃ®nement...\")\n",
        "svm_cw.fit(X_train_cw_scaled, y_train_cw)\n",
        "end_time = time.time()\n",
        "print(f\"Temps d'entraÃ®nement: {end_time - start_time:.2f} secondes\")\n",
        "\n",
        "# --- Predictions ---\n",
        "y_train_pred_cw = svm_cw.predict(X_train_cw_scaled) # Training\n",
        "y_val_pred_cw   = svm_cw.predict(X_val_cw_scaled)   # Validation\n",
        "y_test_pred_cw  = svm_cw.predict(X_test_cw_scaled)  # Test\n",
        "\n",
        "# --- Calcul accuracy ---\n",
        "train_acc_cw = accuracy_score(y_train_cw, y_train_pred_cw)\n",
        "val_acc_cw   = accuracy_score(y_val_cw, y_val_pred_cw)\n",
        "test_acc_cw  = accuracy_score(y_test_cw, y_test_pred_cw)\n",
        "\n",
        "\n",
        "print(\"\\n--- RÃ‰SULTATS ---\")\n",
        "print(\"Train accuracy Â  Â  Â  :\", train_acc_cw)\n",
        "print(\"Validation accuracy Â :\", val_acc_cw)\n",
        "print(\"Test accuracy Â  Â  Â  Â :\", test_acc_cw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Closed world SVM Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- CLOSED WORLD SVM OPTIMIZATION (GRID SEARCH) ---\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "\n",
            "Best parameters found    : {'C': 10, 'kernel': 'rbf'}\n",
            "Accuracy WITHOUT tuning  : 0.6737\n",
            "Accuracy WITH tuning     : 0.8526\n",
            "IMPROVEMENT: +0.1789\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"\\n--- CLOSED WORLD SVM OPTIMIZATION (GRID SEARCH) ---\")\n",
        "\n",
        "# 1. Define parameters to test\n",
        "# We limit the grid because SVM is computationally expensive on large data\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10, 100], \n",
        "    'kernel': ['rbf'] \n",
        "}\n",
        "\n",
        "# 2. Run the search\n",
        "grid_svm_cw = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_svm_cw.fit(X_train_cw_scaled, y_train_cw)\n",
        "\n",
        "# 3. Retrieve the best model\n",
        "best_svm_cw = grid_svm_cw.best_estimator_\n",
        "tuned_acc_cw = best_svm_cw.score(X_test_cw_scaled, y_test_cw)\n",
        "\n",
        "print(f\"\\nBest parameters found    : {grid_svm_cw.best_params_}\")\n",
        "print(f\"Accuracy WITHOUT tuning  : {test_acc_cw:.4f}\")\n",
        "print(f\"Accuracy WITH tuning     : {tuned_acc_cw:.4f}\")\n",
        "\n",
        "# 4. Display the gain\n",
        "gain_cw = tuned_acc_cw - test_acc_cw\n",
        "if gain_cw > 0:\n",
        "    print(f\"IMPROVEMENT: +{gain_cw:.4f}\")\n",
        "else:\n",
        "    print(f\"No significant improvement.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "misZ-ZedwB6F",
        "outputId": "ead9579d-e446-401e-f0b7-1f81642e6bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== OPEN WORLD (SVM) ====\n",
            "DÃ©marrage de l'entraÃ®nement...\n",
            "[LibSVM]Temps d'entraÃ®nement: 43.35 secondes\n",
            "\n",
            "--- RÃ‰SULTATS ---\n",
            "Train accuracy Â  Â  Â  : 0.8974025974025974\n",
            "Validation accuracy Â : 0.8666666666666667\n",
            "Test accuracy Â  Â  Â  Â : 0.8636363636363636\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "print(\"=== OPEN WORLD (SVM) ====\")\n",
        "\n",
        "svm_ow = SVC(\n",
        "    kernel='rbf',\n",
        "    gamma='scale',\n",
        "    C=1.0,\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "start_time = time.time()\n",
        "print(\"DÃ©marrage de l'entraÃ®nement...\")\n",
        "svm_ow.fit(X_train_ow_scaled, y_train_ow)\n",
        "end_time = time.time()\n",
        "print(f\"Temps d'entraÃ®nement: {end_time - start_time:.2f} secondes\")\n",
        "\n",
        "# --- Predictions ---\n",
        "y_train_pred_ow = svm_ow.predict(X_train_ow_scaled) # Training\n",
        "y_val_pred_ow   = svm_ow.predict(X_val_ow_scaled)   # Validation\n",
        "y_test_pred_ow  = svm_ow.predict(X_test_ow_scaled)  # Test\n",
        "\n",
        "# --- Calcul accuracy ---\n",
        "train_acc_ow = accuracy_score(y_train_ow, y_train_pred_ow)\n",
        "val_acc_ow   = accuracy_score(y_val_ow, y_val_pred_ow)\n",
        "test_acc_ow  = accuracy_score(y_test_ow, y_test_pred_ow)\n",
        "\n",
        "\n",
        "print(\"\\n--- RÃ‰SULTATS ---\")\n",
        "print(\"Train accuracy Â  Â  Â  :\", train_acc_ow)\n",
        "print(\"Validation accuracy Â :\", val_acc_ow)\n",
        "print(\"Test accuracy Â  Â  Â  Â :\", test_acc_ow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Open world SVM Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- OPEN WORLD SVM OPTIMIZATION (GRID SEARCH) ---\n",
            "Warning: This process might be slow...\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "\n",
            "Best parameters found    : {'C': 10, 'kernel': 'rbf'}\n",
            "Accuracy WITHOUT tuning  : 0.8636\n",
            "Accuracy WITH tuning     : 0.9333\n",
            "IMPROVEMENT: +0.0697\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"\\n--- OPEN WORLD SVM OPTIMIZATION (GRID SEARCH) ---\")\n",
        "print(\"Warning: This process might be slow...\")\n",
        "\n",
        "# 1. Define parameters to test\n",
        "# We use a limited grid to keep computation time reasonable\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],   # Regularization parameter\n",
        "    'kernel': ['rbf']    # RBF is usually best for this task\n",
        "}\n",
        "\n",
        "# 2. Run the search\n",
        "# cv=3 is used for speed. n_jobs=-1 uses all CPU cores.\n",
        "grid_svm_ow = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_svm_ow.fit(X_train_ow_scaled, y_train_ow)\n",
        "\n",
        "# 3. Retrieve the best model\n",
        "best_svm_ow = grid_svm_ow.best_estimator_\n",
        "tuned_acc_ow = best_svm_ow.score(X_test_ow_scaled, y_test_ow)\n",
        "\n",
        "print(f\"\\nBest parameters found    : {grid_svm_ow.best_params_}\")\n",
        "print(f\"Accuracy WITHOUT tuning  : {test_acc_ow:.4f}\")\n",
        "print(f\"Accuracy WITH tuning     : {tuned_acc_ow:.4f}\")\n",
        "\n",
        "# 4. Display the gain\n",
        "gain_ow = tuned_acc_ow - test_acc_ow\n",
        "if gain_ow > 0:\n",
        "    print(f\"IMPROVEMENT: +{gain_ow:.4f}\")\n",
        "else:\n",
        "    print(f\"No significant improvement.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
