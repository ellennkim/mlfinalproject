{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7b3a0l2ep4"
      },
      "source": [
        "1. mon_standard.pkl > array code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5mfwrTwPtd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n",
            "Total samples: 19000\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 950\n",
        "\n",
        "# Load the pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(\"mon_standard.pkl\", 'rb') as fi: # Path to mon_standard.pkl in Colab\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "X1_mon = [] # Array to store instances (timestamps) - 19,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2_mon = [] # Array to store instances (direction*size) - size information\n",
        "y_mon = [] # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
        "    for sample in data[i]:\n",
        "        size_seq = []\n",
        "        time_seq = []\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1\n",
        "            time_seq.append(abs(c))\n",
        "            size_seq.append(dr * 512)\n",
        "        X1_mon.append(time_seq)\n",
        "        X2_mon.append(size_seq)\n",
        "        y_mon.append(label)\n",
        "size = len(y_mon)\n",
        "\n",
        "print(f'Total samples: {size}') # Output: 19000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz5mat0w2dJy"
      },
      "source": [
        "2. unmon_standard10.pkl > array code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IWfcIOZovSMl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datafile...\n",
            "Total samples: 10000\n",
            "10000\n",
            "[-512, -512, 512, -512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, 512, 512, -512, 512, 512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, 512, 512, 512, -512, -512, 512, 512, -512, -512, 512, -512, -512, -512, -512, 512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, 512, 512, 512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, 512, -512, 512, 512, -512, -512, -512, -512, -512, -512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, 512, 512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, 512, 512, -512, 512, 512, -512, 512, 512, -512, -512, -512, -512, -512, -512, 512, 512, 512, -512, -512, -512, -512, -512, -512, 512, 512, -512, 512, -512, -512, -512, -512, 512, 512, -512, -512, 512, 512, 512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, -512, 512, -512, -512, -512, -512, -512, -512]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "TOTAL_URLS = 10000  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open('unmon_standard10.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "X1_unmon = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2_unmon = [] # Array to store instances (direction*size) - size information\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "    for c in x[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
        "    X1_unmon.append(time_seq)\n",
        "    X2_unmon.append(size_seq)\n",
        "\n",
        "print(len(X1_unmon)) # Print the length of X1\n",
        "\n",
        "print(X2_unmon[0-10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove corrupted/incomplete traces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean monitored traces: 19000\n",
            "Clean unmonitored traces: 10000\n"
          ]
        }
      ],
      "source": [
        "def clean(X1, X2, y=None):\n",
        "    X1_clean, X2_clean, y_clean = [], [], []\n",
        "    for i in range(len(X1)):\n",
        "        if len(X1[i]) > 0 and len(X1[i]) == len(X2[i]): # non-empty & matching lengths\n",
        "            X1_clean.append(X1[i])\n",
        "            X2_clean.append(X2[i])\n",
        "            if y is not None:\n",
        "                y_clean.append(y[i])\n",
        "    return (X1_clean, X2_clean, y_clean) if y is not None else (X1_clean, X2_clean)\n",
        "\n",
        "# clean monitored\n",
        "X1_mon, X2_mon, y_mon = clean(X1_mon, X2_mon, y_mon)\n",
        "print(\"Clean monitored traces:\", len(X1_mon))\n",
        "\n",
        "# clean unmonitored\n",
        "X1_unmon, X2_unmon = clean(X1_unmon, X2_unmon)\n",
        "print(\"Clean unmonitored traces:\", len(X1_unmon))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalize timestamps to start at 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_timestamps(X1):\n",
        "    return [[t - seq[0] for t in seq] for seq in X1] # subtract by first seq value for each value to see how much time passed in each packet\n",
        "\n",
        "X1_mon = normalize_timestamps(X1_mon)\n",
        "X1_unmon = normalize_timestamps(X1_unmon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Truncate or pad sequences to certain length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitored percentiles:\n",
            "50: 3309.0\n",
            "75: 6378.0\n",
            "90: 9929.0\n",
            "95: 9963.0\n",
            "99: 9981.0\n",
            "\n",
            "Unmonitored percentiles:\n",
            "50: 4193.0\n",
            "75: 8233.25\n",
            "90: 9960.0\n",
            "95: 9973.0\n",
            "99: 9984.0\n",
            "\n",
            "Monitored timestamps: (19000, 10000)\n",
            "Unmonitored timestamps: (10000, 10000)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# lengths of all monitored sequences\n",
        "mon_lengths = [len(seq) for seq in X1_mon]\n",
        "\n",
        "# lengths of all unmonitored sequences\n",
        "unmon_lengths = [len(seq) for seq in X1_unmon]\n",
        "\n",
        "print(\"Monitored percentiles:\")\n",
        "for p in [50, 75, 90, 95, 99]:\n",
        "    print(f\"{p}:\", np.percentile(mon_lengths, p))\n",
        "\n",
        "print(\"\\nUnmonitored percentiles:\")\n",
        "for p in [50, 75, 90, 95, 99]:\n",
        "    print(f\"{p}:\", np.percentile(unmon_lengths, p))\n",
        "\n",
        "'''\n",
        "Monitored percentiles:\n",
        "50: 3309.0\n",
        "75: 6378.0\n",
        "90: 9929.0\n",
        "95: 9963.0\n",
        "99: 9981.0\n",
        "\n",
        "Unmonitored percentiles:\n",
        "50: 4193.0\n",
        "75: 8233.25\n",
        "90: 9960.0\n",
        "95: 9973.0\n",
        "99: 9984.0\n",
        "\n",
        "Since at least 90% of the traces have a length > 9,900 packets, the max length should be around 10,000 just to be safe\n",
        "'''\n",
        "\n",
        "MAX_LEN = 10000\n",
        "\n",
        "# truncates sequences if longer than 10,000, pads sequences if shorter than 10,000 with zeros\n",
        "def pad_truncate(seq, max_len=MAX_LEN):\n",
        "    seq = seq[:max_len] # truncate\n",
        "\n",
        "    if len(seq) < max_len: # pad\n",
        "        seq = seq + [0] * (max_len - len(seq))\n",
        "\n",
        "    return seq\n",
        "\n",
        "# new padded/truncated monitored traces\n",
        "X1_mon = np.array([pad_truncate(s) for s in X1_mon])\n",
        "X2_mon = np.array([pad_truncate(s) for s in X2_mon])\n",
        "y_mon = np.array(y_mon)\n",
        "\n",
        "# new padded/truncated unmonitored traces\n",
        "X1_unmon = np.array([pad_truncate(s) for s in X1_unmon])\n",
        "X2_unmon = np.array([pad_truncate(s) for s in X2_unmon])\n",
        "\n",
        "# check to see that both have length of 10,000\n",
        "print(\"\\nMonitored timestamps:\", X1_mon.shape) # should be (19000 traces, 10000 length)\n",
        "print(\"Unmonitored timestamps:\", X1_unmon.shape) # should be (1000 traces, 10000 length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Split data into training, testing, and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 13300\n",
            "Validation: 2850\n",
            "Testing: 2850\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# first, split data into test/validation (30%) and train (70%)\n",
        "\n",
        "X1_train, X1_temp, X2_train, X2_temp, y_train, y_temp = train_test_split(\n",
        "    X1_mon, X2_mon, y_mon,\n",
        "    test_size=0.30,\n",
        "    stratify=y_mon, # use stratified splitting to preserve class balance, especially since we are doing multi-class classification\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# then, split data into test (15%) and validation (15%)\n",
        "\n",
        "X1_val, X1_test, X2_val, X2_test, y_val, y_test = train_test_split(\n",
        "    X1_temp, X2_temp, y_temp,\n",
        "    test_size=0.50,\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# check to see that datasets were split correctly\n",
        "print(\"Training:\", len(X1_train))\n",
        "print(\"Validation:\", len(X1_val))\n",
        "print(\"Testing:\", len(X1_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "cs349",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
